{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from textblob import TextBlob\n",
    "\n",
    "def process(df):\n",
    "    # This is where you can do all your processing\n",
    "    \n",
    "    df['Helpfulness'] = df['HelpfulnessNumerator'] / df['HelpfulnessDenominator']\n",
    "    df['Helpfulness'] = df['Helpfulness'].fillna(0)\n",
    "    df['ReviewLength'] = df.apply(lambda row : len(row['Text'].split()) if type(row['Text']) == str else 0, axis = 1)\n",
    "    \n",
    "    # Add sentiment analysis using TextBlob\n",
    "    df['Summary_sentiment_polarity'] = df['Summary'].apply(lambda x: TextBlob(str(x)).sentiment.polarity)\n",
    "    df['Summary_sentiment_subjectivity'] = df['Summary'].apply(lambda x: TextBlob(str(x)).sentiment.subjectivity)\n",
    "    df['Text_sentiment_polarity'] = df['Text'].apply(lambda x: TextBlob(str(x)).sentiment.polarity)\n",
    "    df['Text_sentiment_subjectivity'] = df['Text'].apply(lambda x: TextBlob(str(x)).sentiment.subjectivity)\n",
    "    \n",
    "    scaler = MinMaxScaler()\n",
    "    df['ReviewLength_normalized'] = scaler.fit_transform(df[['ReviewLength']])\n",
    "    df['Time_normalized'] = scaler.fit_transform(df[['Time']])\n",
    "    df['Summary_sentiment_polarity_normalized'] = scaler.fit_transform(df[['Summary_sentiment_polarity']])\n",
    "    df['Text_sentiment_polarity_normalized'] = scaler.fit_transform(df[['Text_sentiment_polarity']])\n",
    "\n",
    "    # Create a new column with the number of reviews of the ProductId\n",
    "#     df[\"num_product_reviews\"] = df.groupby(\"ProductId\")[\"Id\"].transform(\"count\")\n",
    "    \n",
    "    # Create a new column with the mean socre of the ProductId\n",
    "    df['avg_score'] = df.groupby('ProductId')['Score'].transform('mean')\n",
    "\n",
    "    # Create a new column with the mean socre of the ProductId times the number of reviews of the ProductId\n",
    "#     df['num_product_reviews_X_avg_score'] = df['num_product_reviews'] * df['avg_score']\n",
    "\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating your model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "        Id   ProductId          UserId  HelpfulnessNumerator  \\\n",
      "0  1049849  B000MR9D5E  A1EKSETIBS9ETQ                     0   \n",
      "1   999834  B000GAKFIG   AR0HFYHYHDGQQ                     2   \n",
      "2   218826  6300215776  A37S3ACL57LN62                    11   \n",
      "3   796384  B00019071C  A1TO1P3NV7OAU6                     2   \n",
      "4  1219784  B001NFNFN0   ATCM1W7HWIC6U                     0   \n",
      "\n",
      "   HelpfulnessDenominator        Time  \\\n",
      "0                       0  1198281600   \n",
      "1                       5  1245024000   \n",
      "2                      15  1126137600   \n",
      "3                       2  1351036800   \n",
      "4                       0  1381708800   \n",
      "\n",
      "                                             Summary  \\\n",
      "0  Great nature series, but not all scenes looked...   \n",
      "1                 Agatha Christie's Marple: Series 2   \n",
      "2                             Childish Entertainment   \n",
      "3                       The weakest Babylon 5 season   \n",
      "4                            Versatile and effective   \n",
      "\n",
      "                                                Text  Score  Helpfulness  ...  \\\n",
      "0  I have watched numbers of nature shows and ser...    4.0     0.000000  ...   \n",
      "1  As a devoted fan of all of Agatha Christie's f...    5.0     0.400000  ...   \n",
      "2  This movie is about a script writer and a secr...    2.0     0.733333  ...   \n",
      "3  This is the weakest Babylon 5 season. After wi...    4.0     1.000000  ...   \n",
      "4  This video will always have a sweet spot on my...    5.0     0.000000  ...   \n",
      "\n",
      "   Summary_sentiment_subjectivity  Text_sentiment_polarity  \\\n",
      "0                            0.75                 0.186411   \n",
      "1                            0.00                 0.040000   \n",
      "2                            0.80                 0.069771   \n",
      "3                            0.00                 0.041667   \n",
      "4                            0.80                 0.217632   \n",
      "\n",
      "   Text_sentiment_subjectivity  ReviewLength_normalized  Time_normalized  \\\n",
      "0                     0.479472                 0.027862         0.593544   \n",
      "1                     0.590000                 0.013002         0.684975   \n",
      "2                     0.519537                 0.037487         0.452425   \n",
      "3                     0.598958                 0.018575         0.892344   \n",
      "4                     0.538690                 0.032084         0.952341   \n",
      "\n",
      "   Summary_sentiment_polarity_normalized  Text_sentiment_polarity_normalized  \\\n",
      "0                                    0.9                            0.593205   \n",
      "1                                    0.5                            0.520000   \n",
      "2                                    0.4                            0.534886   \n",
      "3                                    0.5                            0.520833   \n",
      "4                                    0.8                            0.608816   \n",
      "\n",
      "   num_product_reviews  avg_score  num_product_reviews_X_avg_score  \n",
      "0                   38   4.593750                       174.562500  \n",
      "1                    9   4.666667                        42.000000  \n",
      "2                    5   2.600000                        13.000000  \n",
      "3                    9   4.375000                        39.375000  \n",
      "4                   19   4.470588                        84.941176  \n",
      "\n",
      "[5 rows x 22 columns]\n"
     ]
    }
   ],
   "source": [
    "# Load the dataset\n",
    "trainingSet = pd.read_csv(\"./data/train.csv\")\n",
    "\n",
    "# Process the DataFrame\n",
    "train_processed = process(trainingSet)\n",
    "\n",
    "# Load test set\n",
    "submissionSet = pd.read_csv(\"./data/test.csv\")\n",
    "\n",
    "# Merge on Id so that the test set can have feature columns as well\n",
    "testX= pd.merge(train_processed, submissionSet, left_on='Id', right_on='Id')\n",
    "testX = testX.drop(columns=['Score_x'])\n",
    "testX = testX.rename(columns={'Score_y': 'Score'})\n",
    "\n",
    "# The training set is where the score is not null\n",
    "# This line creates a new DataFrame called trainX by selecting only the rows in train_processed \n",
    "#     where the \"Score\" column is not null. \n",
    "# This assumes that the \"Score\" column is the target variable that we want to predict.\n",
    "trainX =  train_processed[train_processed['Score'].notnull()]\n",
    "\n",
    "# Save the datasets with the new features for easy access later\n",
    "testX.to_csv(\"./test_data/X_test.csv\", index=False)\n",
    "trainX.to_csv(\"./test_data/X_train.csv\", index=False)\n",
    "# print(testX.head())\n",
    "print()\n",
    "print(trainX.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "B001KVZ6HK\n"
     ]
    }
   ],
   "source": [
    "# check code\n",
    "# ProductId that has the biggest values in column \"num_product_reviews\"\n",
    "print(trainX.groupby('ProductId')['Id'].count().idxmax())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   HelpfulnessNumerator  HelpfulnessDenominator        Time  Score  \\\n",
      "0                     0                       0  1198281600    4.0   \n",
      "1                     2                       5  1245024000    5.0   \n",
      "2                    11                      15  1126137600    2.0   \n",
      "3                     2                       2  1351036800    4.0   \n",
      "4                     0                       0  1381708800    5.0   \n",
      "\n",
      "   Helpfulness  ReviewLength  Summary_sentiment_polarity  \\\n",
      "0     0.000000           165                         0.8   \n",
      "1     0.400000            77                         0.0   \n",
      "2     0.733333           222                        -0.2   \n",
      "3     1.000000           110                         0.0   \n",
      "4     0.000000           190                         0.6   \n",
      "\n",
      "   Summary_sentiment_subjectivity  Text_sentiment_polarity  \\\n",
      "0                            0.75                 0.186411   \n",
      "1                            0.00                 0.040000   \n",
      "2                            0.80                 0.069771   \n",
      "3                            0.00                 0.041667   \n",
      "4                            0.80                 0.217632   \n",
      "\n",
      "   Text_sentiment_subjectivity  ReviewLength_normalized  Time_normalized  \\\n",
      "0                     0.479472                 0.027862         0.593544   \n",
      "1                     0.590000                 0.013002         0.684975   \n",
      "2                     0.519537                 0.037487         0.452425   \n",
      "3                     0.598958                 0.018575         0.892344   \n",
      "4                     0.538690                 0.032084         0.952341   \n",
      "\n",
      "   Summary_sentiment_polarity_normalized  Text_sentiment_polarity_normalized  \\\n",
      "0                                    0.9                            0.593205   \n",
      "1                                    0.5                            0.520000   \n",
      "2                                    0.4                            0.534886   \n",
      "3                                    0.5                            0.520833   \n",
      "4                                    0.8                            0.608816   \n",
      "\n",
      "   num_product_reviews  avg_score  num_product_reviews_X_avg_score  \n",
      "0                   38   4.593750                       174.562500  \n",
      "1                    9   4.666667                        42.000000  \n",
      "2                    5   2.600000                        13.000000  \n",
      "3                    9   4.375000                        39.375000  \n",
      "4                   19   4.470588                        84.941176  \n"
     ]
    }
   ],
   "source": [
    "trainX = trainX.drop(columns=['Id', 'ProductId', 'UserId', 'Text', 'Summary'])\n",
    "print(trainX.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'items'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/19/c06pzryx24qcvck9yh7zg28r0000gn/T/ipykernel_29846/4107642153.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;31m# Print the column name and correlation, in decreasing order\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mcol\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcorr\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcorrelations\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"{col}: {corr:.2f}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'items'"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, mean_squared_error\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# Load training set with new features into DataFrame\n",
    "X_train_NLP_9feature_500_700 = pd.read_csv(\"./data/X_train_NLP_9feature_500-700.csv\")\n",
    "\n",
    "\n",
    "# correlations = X_train_NLP_9feature_500_700.corr()['Score'].sort_values(ascending=False)\n",
    "\n",
    "# return absolute value and return the top 20 columns\n",
    "correlations = X_train_NLP_9feature_500_700.corr()['Score'].abs().sort_values(ascending=False)[:20].index.tolist()\n",
    "# print(correlations)\n",
    "\n",
    "\n",
    "# Print the column name and correlation, in decreasing order\n",
    "for col, corr in correlations.items():\n",
    "    print(f\"{col}: {corr:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "7697e155108679fa2d22949e509aeff305faa212a8830735ae3989f6ecc6d1af"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
