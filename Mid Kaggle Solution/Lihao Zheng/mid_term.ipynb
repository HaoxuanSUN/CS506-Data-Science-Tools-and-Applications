{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "72faaba4",
   "metadata": {},
   "source": [
    "# Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c2156cd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: lightgbm in c:\\users\\nee\\appdata\\roaming\\python\\python39\\site-packages (3.3.5)\n",
      "Requirement already satisfied: wheel in d:\\anaconda3\\lib\\site-packages (from lightgbm) (0.37.1)\n",
      "Requirement already satisfied: numpy in d:\\anaconda3\\lib\\site-packages (from lightgbm) (1.21.5)\n",
      "Requirement already satisfied: scikit-learn!=0.22.0 in d:\\anaconda3\\lib\\site-packages (from lightgbm) (1.0.2)\n",
      "Requirement already satisfied: scipy in d:\\anaconda3\\lib\\site-packages (from lightgbm) (1.7.3)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in d:\\anaconda3\\lib\\site-packages (from scikit-learn!=0.22.0->lightgbm) (2.2.0)\n",
      "Requirement already satisfied: joblib>=0.11 in d:\\anaconda3\\lib\\site-packages (from scikit-learn!=0.22.0->lightgbm) (1.1.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install lightgbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "614301d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train.csv shape is  (139753, 9)\n",
      "test.csv shape is  (13976, 2)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "trainingSet = pd.read_csv(\"./data/train.csv\")\n",
    "testingSet = pd.read_csv(\"./data/test.csv\")\n",
    "\n",
    "print(\"train.csv shape is \", trainingSet.shape)\n",
    "print(\"test.csv shape is \", testingSet.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e09f9a53",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.0    67188\n",
       "4.0    28572\n",
       "3.0    14857\n",
       "1.0     7593\n",
       "2.0     7567\n",
       "Name: Score, dtype: int64"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainingSet['Score'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6817c03a",
   "metadata": {},
   "source": [
    "# Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "77d74c5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process(df):\n",
    "    df['Helpfulness'] = df['HelpfulnessNumerator'] / df['HelpfulnessDenominator']\n",
    "    df['Helpfulness'] = df['Helpfulness'].fillna(0)\n",
    "    df['ReviewLength'] = df.apply(lambda row : len(row['Text'].split()) if type(row['Text']) == str else 0, axis = 1)\n",
    "    return df\n",
    "\n",
    "# Load the dataset\n",
    "trainingSet = pd.read_csv(\"./data/train.csv\")\n",
    "\n",
    "# Process the DataFrame\n",
    "train_processed = process(trainingSet)\n",
    "\n",
    "# Load test set\n",
    "submissionSet = pd.read_csv(\"./data/test.csv\")\n",
    "\n",
    "# Merge on Id so that the test set can have feature columns as well\n",
    "testX= pd.merge(train_processed, submissionSet, left_on='Id', right_on='Id')\n",
    "testX = testX.drop(columns=['Score_x'])\n",
    "testX = testX.rename(columns={'Score_y': 'Score'})\n",
    "\n",
    "# The training set is where the score is not null\n",
    "trainX =  train_processed[train_processed['Score'].notnull()]\n",
    "\n",
    "# Save the datasets with the new features for easy access later\n",
    "testX.to_csv(\"./data/X_test.csv\", index=False)\n",
    "trainX.to_csv(\"./data/X_train.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "14770afc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>ProductId</th>\n",
       "      <th>UserId</th>\n",
       "      <th>HelpfulnessNumerator</th>\n",
       "      <th>HelpfulnessDenominator</th>\n",
       "      <th>Time</th>\n",
       "      <th>Summary</th>\n",
       "      <th>Text</th>\n",
       "      <th>Helpfulness</th>\n",
       "      <th>ReviewLength</th>\n",
       "      <th>Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1224650</td>\n",
       "      <td>B001OQCV6A</td>\n",
       "      <td>A3HUN3KP383B23</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1395619200</td>\n",
       "      <td>Sherlock Holmes</td>\n",
       "      <td>I bought this thinking it was Sherlock Holmes ...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>47</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1019381</td>\n",
       "      <td>B000I8OFLO</td>\n",
       "      <td>A2VJ80PM1G00QV</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1222300800</td>\n",
       "      <td>FINE SINGING, DESTRUCTIVE STAGING</td>\n",
       "      <td>1. Scenic design and the Directors use of it p...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>160</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>504719</td>\n",
       "      <td>B00000IQCC</td>\n",
       "      <td>A2EGK0YRDF4ZZB</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>1018310400</td>\n",
       "      <td>Moving story of Jesus's message in a modern re...</td>\n",
       "      <td>J&amp;eacute;sus de Montr&amp;eacute;al  was a stunni...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>999</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1622425</td>\n",
       "      <td>B00B5UBDA0</td>\n",
       "      <td>A21I62TCDL4754</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1372118400</td>\n",
       "      <td>Paul Anka has aged well and performs well</td>\n",
       "      <td>I was looking for Blu Ray concerts for my new ...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>31</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>482286</td>\n",
       "      <td>6305892946</td>\n",
       "      <td>A1IQ9E6I3PIUFF</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>969321600</td>\n",
       "      <td>Great end to the series.Or is it???????????</td>\n",
       "      <td>Despite what everyone else says this movie is ...</td>\n",
       "      <td>0.5</td>\n",
       "      <td>30</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Id   ProductId          UserId  HelpfulnessNumerator  \\\n",
       "0  1224650  B001OQCV6A  A3HUN3KP383B23                     0   \n",
       "1  1019381  B000I8OFLO  A2VJ80PM1G00QV                     2   \n",
       "2   504719  B00000IQCC  A2EGK0YRDF4ZZB                    11   \n",
       "3  1622425  B00B5UBDA0  A21I62TCDL4754                     0   \n",
       "4   482286  6305892946  A1IQ9E6I3PIUFF                     1   \n",
       "\n",
       "   HelpfulnessDenominator        Time  \\\n",
       "0                       1  1395619200   \n",
       "1                       2  1222300800   \n",
       "2                      11  1018310400   \n",
       "3                       0  1372118400   \n",
       "4                       2   969321600   \n",
       "\n",
       "                                             Summary  \\\n",
       "0                                    Sherlock Holmes   \n",
       "1                  FINE SINGING, DESTRUCTIVE STAGING   \n",
       "2  Moving story of Jesus's message in a modern re...   \n",
       "3          Paul Anka has aged well and performs well   \n",
       "4        Great end to the series.Or is it???????????   \n",
       "\n",
       "                                                Text  Helpfulness  \\\n",
       "0  I bought this thinking it was Sherlock Holmes ...          0.0   \n",
       "1  1. Scenic design and the Directors use of it p...          1.0   \n",
       "2   J&eacute;sus de Montr&eacute;al  was a stunni...          1.0   \n",
       "3  I was looking for Blu Ray concerts for my new ...          0.0   \n",
       "4  Despite what everyone else says this movie is ...          0.5   \n",
       "\n",
       "   ReviewLength  Score  \n",
       "0            47    NaN  \n",
       "1           160    NaN  \n",
       "2           999    NaN  \n",
       "3            31    NaN  \n",
       "4            30    NaN  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testX.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba0154c1",
   "metadata": {},
   "source": [
    "# Text Data Preprocess + TFIDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cf58bba3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\NEE\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6cfc5d50",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\NEE\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fa4ce8f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\NEE\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25156, 12)\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Load the dataset into a pandas DataFrame\n",
    "data = trainX.loc[:]\n",
    "data.loc[30004,'Summary'] = ' '\n",
    "data.loc[100011,'Text'] = ' '\n",
    "test = testX.loc[:, ['Summary', 'Text', 'Score']]\n",
    "# Preprocess the text data\n",
    "stop_words = set(stopwords.words('english'))\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "import nltk\n",
    "nltk.download('wordnet')\n",
    "def preprocess_text(text):\n",
    "    words = re.sub(r'[^\\w\\s]', '', text)\n",
    "    words = words.lower()\n",
    "    words = words.split()\n",
    "    words = [word for word in words if word not in stop_words and word.isalpha()]\n",
    "    words = [lemmatizer.lemmatize(word) for word in words]\n",
    "    return ' '.join(words)\n",
    "data['Review'] = data['Summary'] + ' ' + data['Text']\n",
    "test['Review'] = test['Summary'] + ' ' + test['Text']\n",
    "\n",
    "data['Review'] = data['Review'].apply(preprocess_text)\n",
    "test['Review'] = test['Review'].apply(preprocess_text)\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(data, data[\"Score\"], test_size=0.2, random_state=42)\n",
    "print(X_test.shape)\n",
    "\n",
    "# Convert the text data into numerical features using TF-IDF\n",
    "Xtrain = X_train['Review']\n",
    "Xtest = X_test['Review']\n",
    "vectorizer = TfidfVectorizer(ngram_range=(1, 2), max_features=9000)\n",
    "Xtrain = vectorizer.fit_transform(Xtrain)\n",
    "Xtest = vectorizer.transform(Xtest)\n",
    "sample = vectorizer.transform(test['Review'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a79f81d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<13976x9000 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 913424 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ada5267",
   "metadata": {},
   "source": [
    "# Sentiment Analysis Model: LGBM + Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b75e3323",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean squared error: 0.70\n"
     ]
    }
   ],
   "source": [
    "import lightgbm as lgb\n",
    "from sklearn.metrics import mean_squared_error\n",
    "# Instantiate the LightGBM regressor\n",
    "lgb_regressor = lgb.LGBMRegressor(num_leaves = 200,random_state=42)\n",
    "lgb_regressor.fit(Xtrain, y_train)\n",
    "y_lgb = lgb_regressor.predict(Xtest)\n",
    "\n",
    "# Calculate the mean squared error\n",
    "mse = mean_squared_error(y_test, y_lgb)\n",
    "print(f\"Mean squared error: {mse:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bdf922f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4.38982116, 3.12718382, 4.69584868, ..., 3.07332093, 4.3725948 ,\n",
       "       4.52553703])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_lgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "21232804",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.63\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.62      0.52      0.57      1517\n",
      "         2.0       0.38      0.25      0.30      1539\n",
      "         3.0       0.44      0.35      0.39      2964\n",
      "         4.0       0.44      0.37      0.40      5654\n",
      "         5.0       0.74      0.86      0.79     13482\n",
      "\n",
      "    accuracy                           0.63     25156\n",
      "   macro avg       0.52      0.47      0.49     25156\n",
      "weighted avg       0.61      0.63      0.61     25156\n",
      "\n",
      "[[  789   284   129    65   250]\n",
      " [  228   382   445   213   271]\n",
      " [  108   225  1031   879   721]\n",
      " [   52    69   510  2083  2940]\n",
      " [   94    58   236  1474 11620]]\n",
      "MSE:  0.8907218953728733\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import numpy as np\n",
    "# dataset\n",
    "Xtrain, Xtest, y_train, y_test\n",
    "\n",
    "# create a Naive Bayes classifier\n",
    "nb = MultinomialNB(alpha = 0.0005,fit_prior = False)\n",
    "\n",
    "# create an AdaBoost classifier with 100 estimators and a learning rate of 0.18\n",
    "boost_clf = AdaBoostClassifier(base_estimator=nb, n_estimators=100, learning_rate = 0.18)\n",
    "\n",
    "# train the AdaBoost classifier on the training data\n",
    "boost_clf.fit(Xtrain, y_train)\n",
    "\n",
    "# predict the classes of the test data\n",
    "y_pred = boost_clf.predict(Xtest)\n",
    "\n",
    "# prin metrics\n",
    "accuracy = (y_pred == y_test).sum() / len(y_test)\n",
    "print(f\"Accuracy: {accuracy:.2f}\")\n",
    "report = classification_report(y_test, y_pred)\n",
    "print(f\"Classification Report:\\n{report}\")\n",
    "print(confusion_matrix(y_test,y_pred))\n",
    "print('MSE: ',np.mean(np.square(y_pred - y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "67de2d33",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4., 4., 5., ..., 5., 4., 5.])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8134dd10",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'1': 0.6652495937233721,\n",
       " '2': 0.6470976683091553,\n",
       " '3': 0.6487102384399707,\n",
       " '4': 0.6530981110266044,\n",
       " '5': 0.657448497129416}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#combine the models and comput the weight for reducing mse\n",
    "para_mse = {}\n",
    "for i in range(1,6):\n",
    "    para_mse[str(i)] = sum((np.square(y_test - (y_pred  + y_lgb * i) / (i+1))))/ len(y_test)\n",
    "para_mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "df4d2884",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100621,) (25156,)\n"
     ]
    }
   ],
   "source": [
    "#combined predictions for new feature\n",
    "train_predict = (boost_clf.predict(Xtrain) + lgb_regressor.predict(Xtrain) * 2) / 3\n",
    "test_predict = (y_pred + y_lgb * 2) / 3\n",
    "print(train_predict.shape, test_predict.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "eeda6f94",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6470976683091553"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(np.square(test_predict - y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "697aca53",
   "metadata": {},
   "source": [
    "# Error Model : LGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6ce7aea6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>ProductId</th>\n",
       "      <th>UserId</th>\n",
       "      <th>HelpfulnessNumerator</th>\n",
       "      <th>HelpfulnessDenominator</th>\n",
       "      <th>Time</th>\n",
       "      <th>Summary</th>\n",
       "      <th>Text</th>\n",
       "      <th>Score</th>\n",
       "      <th>Helpfulness</th>\n",
       "      <th>ReviewLength</th>\n",
       "      <th>Review</th>\n",
       "      <th>predict_error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>14587</th>\n",
       "      <td>748290</td>\n",
       "      <td>B00008WFHE</td>\n",
       "      <td>A3Q3DPQ38DXI4C</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1215302400</td>\n",
       "      <td>Fascinating</td>\n",
       "      <td>I have watched this DVD several times with my ...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>173</td>\n",
       "      <td>fascinating watched dvd several time four mont...</td>\n",
       "      <td>0.236299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124883</th>\n",
       "      <td>225509</td>\n",
       "      <td>6300247120</td>\n",
       "      <td>A1ARZLZRS4JZX7</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>1172793600</td>\n",
       "      <td>They can't make 'em like this anymore.</td>\n",
       "      <td>\"Breaking Away\" is a true rarity: a feel-good ...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>125</td>\n",
       "      <td>cant make em like anymore breaking away true r...</td>\n",
       "      <td>0.473899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44292</th>\n",
       "      <td>1027963</td>\n",
       "      <td>B000JLTR8Q</td>\n",
       "      <td>AXMVY1CH5125B</td>\n",
       "      <td>14</td>\n",
       "      <td>54</td>\n",
       "      <td>1164672000</td>\n",
       "      <td>I'll never trust Amazon's reviewers again.</td>\n",
       "      <td>I honestly don't know how this waste of cellul...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.259259</td>\n",
       "      <td>63</td>\n",
       "      <td>ill never trust amazon reviewer honestly dont ...</td>\n",
       "      <td>-0.353568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52064</th>\n",
       "      <td>1010387</td>\n",
       "      <td>B000H5V8H2</td>\n",
       "      <td>A31ARSC1LGY8WK</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1205884800</td>\n",
       "      <td>Paying the ultimate price for your principles</td>\n",
       "      <td>This film chronicles the final few days - lite...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>145</td>\n",
       "      <td>paying ultimate price principle film chronicle...</td>\n",
       "      <td>0.052400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81112</th>\n",
       "      <td>80876</td>\n",
       "      <td>0788812483</td>\n",
       "      <td>A1DD15RXIXWENM</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1292544000</td>\n",
       "      <td>Disney and Dogs..</td>\n",
       "      <td>in few words:- a true story- beautiful and hea...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>26</td>\n",
       "      <td>disney dog word true story beautiful heartbrea...</td>\n",
       "      <td>-0.526201</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Id   ProductId          UserId  HelpfulnessNumerator  \\\n",
       "14587    748290  B00008WFHE  A3Q3DPQ38DXI4C                     0   \n",
       "124883   225509  6300247120  A1ARZLZRS4JZX7                     5   \n",
       "44292   1027963  B000JLTR8Q   AXMVY1CH5125B                    14   \n",
       "52064   1010387  B000H5V8H2  A31ARSC1LGY8WK                     2   \n",
       "81112     80876  0788812483  A1DD15RXIXWENM                     0   \n",
       "\n",
       "        HelpfulnessDenominator        Time  \\\n",
       "14587                        0  1215302400   \n",
       "124883                       5  1172793600   \n",
       "44292                       54  1164672000   \n",
       "52064                        2  1205884800   \n",
       "81112                        0  1292544000   \n",
       "\n",
       "                                              Summary  \\\n",
       "14587                                     Fascinating   \n",
       "124883         They can't make 'em like this anymore.   \n",
       "44292      I'll never trust Amazon's reviewers again.   \n",
       "52064   Paying the ultimate price for your principles   \n",
       "81112                               Disney and Dogs..   \n",
       "\n",
       "                                                     Text  Score  Helpfulness  \\\n",
       "14587   I have watched this DVD several times with my ...    5.0     0.000000   \n",
       "124883  \"Breaking Away\" is a true rarity: a feel-good ...    5.0     1.000000   \n",
       "44292   I honestly don't know how this waste of cellul...    1.0     0.259259   \n",
       "52064   This film chronicles the final few days - lite...    4.0     1.000000   \n",
       "81112   in few words:- a true story- beautiful and hea...    4.0     0.000000   \n",
       "\n",
       "        ReviewLength                                             Review  \\\n",
       "14587            173  fascinating watched dvd several time four mont...   \n",
       "124883           125  cant make em like anymore breaking away true r...   \n",
       "44292             63  ill never trust amazon reviewer honestly dont ...   \n",
       "52064            145  paying ultimate price principle film chronicle...   \n",
       "81112             26  disney dog word true story beautiful heartbrea...   \n",
       "\n",
       "        predict_error  \n",
       "14587        0.236299  \n",
       "124883       0.473899  \n",
       "44292       -0.353568  \n",
       "52064        0.052400  \n",
       "81112       -0.526201  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# add new feature\n",
    "X_train['predict_error'] = y_train - train_predict\n",
    "X_test['predict_error'] = y_test - test_predict\n",
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "82eae05e",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_Xtrain = X_train[['Helpfulness','ReviewLength']]\n",
    "new_ytrain = X_train['predict_error']\n",
    "new_Xtest = X_test[['Helpfulness','ReviewLength']]\n",
    "new_ytest = X_test['predict_error']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3a8e76f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean squared error: 0.61\n"
     ]
    }
   ],
   "source": [
    "import lightgbm as lgb\n",
    "from sklearn.metrics import mean_squared_error\n",
    "# Instantiate the LightGBM regressor\n",
    "err_lgb = lgb.LGBMRegressor(random_state=42)\n",
    "err_lgb.fit(new_Xtrain, new_ytrain)\n",
    "y_err = err_lgb.predict(new_Xtest)\n",
    "\n",
    "# Calculate the mean squared error\n",
    "mse = mean_squared_error(new_ytest, y_err)\n",
    "print(f\"Mean squared error: {mse:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "573a7531",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.607657110181691"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# mse for TestSet\n",
    "final_pred = y_err + test_predict\n",
    "final =  np.where(final_pred>5, 5, final_pred)\n",
    "final = np.where(final<0, 0, final)\n",
    "mean_squared_error(final, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "54a60cb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# final result\n",
    "result = (boost_clf.predict(sample) + lgb_regressor.predict(sample) * 2) / 3\n",
    "err = err_lgb.predict(testX[['Helpfulness','ReviewLength']])\n",
    "result = result + err"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0bb8f2ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13976,)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d30de91",
   "metadata": {},
   "source": [
    "# Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "cc5e9da7",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_submission = pd.read_csv(\"./data/X_test.csv\")\n",
    "X_submission['Score'] = result\n",
    "submission = X_submission[['Id', 'Score']]\n",
    "submission.to_csv(\"./data/submission.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
